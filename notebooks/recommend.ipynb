{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603c4d20-d45f-49b5-b9de-a7e48ad44d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.cm as cm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafe2753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/specter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "654e5557-1007-42b5-9039-1007dc639d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize empty lists to store ids and embeddings\n",
    "ids = []\n",
    "embeddings = []\n",
    "\n",
    "embedding_files = [f'{DATA_PATH}/output_10k.json']\n",
    "# embedding_files = ['custom output/embedding_result_train.jsonl', 'custom output/embedding_result_val.jsonl', 'custom output/embedding_result_test.jsonl']\n",
    "\n",
    "# Load embeddings from JSON file\n",
    "for file in embedding_files:\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            id = data['paper_id']\n",
    "            # removing the R paper because it has too many citations and makes everything else in graph look tiny\n",
    "            # if id == '659408b243cec55de8d0a3bc51b81173007aa89b':\n",
    "            #     continue\n",
    "            embedding = np.array(data['embedding'])\n",
    "            ids.append(id)\n",
    "            embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43e9ed91-d649-4d79-aaaa-bdd6508df8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'{DATA_PATH}/output_10k.json', 'r') as f:\n",
    "    embeddings = [json.loads(line) for line in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47bbc8ba-4d7e-4d1c-a37b-f7f5567859b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embedding_map = {}\n",
    "# for obj in embeddings:\n",
    "#     # obj is dict like {paper_id: 768 dimensional array embedding}\n",
    "#     embedding_map[obj['paper_id']] = np.asarray(obj['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02e91117-8cc1-46c4-a1a3-e1424798eef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'{DATA_PATH}/metadata_10k_full.json', 'r') as f:\n",
    "    metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51f94c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9922, 9922)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_map), len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38576b36-9bbd-4826-a22f-40540fb87c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'R: A language and environment for statistical computing.',\n",
       " 'abstract': 'Copyright (©) 1999–2012 R Foundation for Statistical Computing. Permission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies. Permission is granted to copy and distribute modified versions of this manual under the conditions for verbatim copying, provided that the entire resulting derived work is distributed under the terms of a permission notice identical to this one. Permission is granted to copy and distribute translations of this manual into another language, under the above conditions for modified versions, except that this permission notice may be stated in a translation approved by the R Core Team.',\n",
       " 'year': 2014,\n",
       " 'referenceCount': 0,\n",
       " 'citationCount': 295928,\n",
       " 'influentialCitationCount': 40046,\n",
       " 'references': '[]',\n",
       " 'paper_id': '659408b243cec55de8d0a3bc51b81173007aa89b'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['659408b243cec55de8d0a3bc51b81173007aa89b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2edc8b75-6d97-47a0-bf5f-5ab531113267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\n"
     ]
    }
   ],
   "source": [
    "for e in embedding_map:\n",
    "    print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c98faf7-f8ad-4d3b-b025-e5268c661c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = torch.stack([torch.tensor(e['embedding']) for e in embeddings]).double()\n",
    "paper_ids = [e['paper_id'] for e in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0f7e307-9a23-424f-bd74-34e2ed9e0e68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9922, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f82d9569-486f-4d15-a88c-e8778c78b849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "specter_tokenizer = AutoTokenizer.from_pretrained('allenai/specter')\n",
    "specter_model = AutoModel.from_pretrained('allenai/specter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d13362ed-719b-4e46-b47f-2d403a459c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "papers = [{'title': 'BERT', 'abstract': 'We introduce a new language representation model called BERT'},\n",
    "          {'title': 'Attention is all you need', 'abstract': ' The dominant sequence transduction models are based on complex recurrent or convolutional neural networks'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ad8d729-3f6a-4fe7-8fa7-437336b38a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_embedding(paper):\n",
    "    # tokenizer = AutoTokenizer.from_pretrained('allenai/specter')\n",
    "    # model = AutoModel.from_pretrained('allenai/specter')\n",
    "    title_abs = [d['title'] + specter_tokenizer.sep_token + (d.get('abstract') or '') for d in [paper]]\n",
    "    inputs = specter_tokenizer(title_abs, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    result = specter_model(**inputs)\n",
    "    cur_embedding = result.last_hidden_state[:, 0, :]\n",
    "    return cur_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18241b87-e827-4dbd-ba82-63cb62af8ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def find_similar_knn(paper, weights, k=10, least = False):\n",
    "    cur_embedding = get_embedding(paper)\n",
    "    weights_norm = F.normalize(weights, p=2, dim=1).double() # (N, d)\n",
    "    cur_em_norm = F.normalize(cur_embedding, p=2, dim=1).double() # (1, d)\n",
    "    cos_sim = F.cosine_similarity(weights, cur_embedding, dim=1)\n",
    "    topk = torch.topk(cos_sim, k, largest = False if least else True)\n",
    "    top_indices = topk.indices\n",
    "    top_values = topk.values\n",
    "    return top_indices, top_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "28471f67-bc00-4c80-b437-9f999547ae51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(recommended, actual, k=None):\n",
    "    recommended = np.asarray(recommended)[:k] if k else np.asarray(recommended)\n",
    "    actual = np.asarray(actual)\n",
    "    \n",
    "    true_positives = np.intersect1d(recommended, actual)\n",
    "    false_positives = np.setdiff1d(recommended, actual)\n",
    "    false_negatives = np.setdiff1d(actual, recommended)\n",
    "\n",
    "    precision = len(true_positives) / (len(true_positives) + len(false_positives))\n",
    "    recall = len(true_positives) / (len(true_positives) + len(false_negatives))\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "    # if k:\n",
    "    #     precision_at_k = len(true_positives) / k\n",
    "    #     recall_at_k = len(true_positives) / len(actual)\n",
    "    #     return precision_at_k, recall_at_k, f1_score\n",
    "    return precision, recall, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc1cdcd8-59dc-4c7c-9df2-d99699b9a362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 204e3073870fae3d05bcbc2f6a8e263d9b72e776\n",
    "new_title = 'Attention Is All You Need'\n",
    "new_abstract = 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a1c639-2724-431d-ae74-397f6b591af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_title = 'SPECTER: Document-level Representation Learning using Citation-informed Transformers'\n",
    "# new_abstract = 'Representation learning is a critical ingredient for natural language processing systems. Recent Transformer language models like BERT learn powerful textual representations, but these models are targeted towards token- and sentence-level training objectives and do not leverage information on inter-document relatedness, which limits their document-level representation power. For applications on scientific documents, such as classification and recommendation, the embeddings power strong performance on end tasks. We propose SPECTER, a new method to generate document-level embedding of scientific documents based on pretraining a Transformer language model on a powerful signal of document-level relatedness: the citation graph. Unlike existing pretrained language models, SPECTER can be easily applied to downstream applications without task-specific fine-tuning. Additionally, to encourage further research on document-level models, we introduce SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation. We show that SPECTER outperforms a variety of competitive baselines on the benchmark.'\n",
    "\n",
    "new_abstract = 'We propose SPECTER, a new method to generate document-level embedding of scientific documents based on pretraining a Transformer language model on a powerful signal of document-level relatedness: the citation graph. Unlike existing pretrained language models, SPECTER can be easily applied to downstream applications without task-specific fine-tuning. Additionally, to encourage further research on document-level models, we introduce SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation. We show that SPECTER outperforms a variety of competitive baselines on the benchmark.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "30fce82f-4155-4f2f-aacd-c37dc7293d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new_paper = {'title': new_title, 'abstract': new_abstract or ''}\n",
    "# assert new_paper['title'] is not None\n",
    "paper_id = '204e3073870fae3d05bcbc2f6a8e263d9b72e776'\n",
    "# paper_id = '156d217b0a911af97fa1b5a71dc909ccef7a8028'\n",
    "top_indices, top_values = find_similar_knn(metadata[paper_id], weights, k=10, least=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5002a90d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['204e3073870fae3d05bcbc2f6a8e263d9b72e776', 'b60abe57bc195616063be10638c6437358c81d1e', '9ae0a24f0928cab1554a6ac880f6b350f85be698', 'dbde7dfa6cae81df8ac19ef500c42db96c3d1edd', '43428880d75b3a14257c3ee9bda054e61eb869c0', '93499a7c7f699b6630a86fad964536f9423bb6d0', '4550a4c714920ef57d19878e31c9ebae37b049b2', 'bb669de2fce407df2f5cb2f8c51dedee3f467e04', '25eb839f39507fe6983ad3e692b2f8d93a5cb0cc', 'bf8fe437f779f2098f9af82b534aa51dc9edb06f']\n"
     ]
    }
   ],
   "source": [
    "recommended_paper_ids = [paper_ids[i] for i in top_indices]\n",
    "print(recommended_paper_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dfee6cb2-202c-4812-960d-610de0f8e040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper ID: 156d217b0a911af97fa1b5a71dc909ccef7a8028\n",
      "Title: SciBERT: A Pretrained Language Model for Scientific Text\n",
      "Year: 2019\n",
      "Cosine similarity: 0.9986527573226276\n",
      "\n",
      "Paper ID: 87078d95bee341a1767034d9432fb34937ecf65a\n",
      "Title: SciBERT: Pretrained Contextualized Embeddings for Scientific Text\n",
      "Year: 2019\n",
      "Cosine similarity: 0.9512990508639432\n",
      "\n",
      "Paper ID: 54523ff961a1ac57a86696ef9a53b3a630b482c0\n",
      "Title: Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing\n",
      "Year: 2020\n",
      "Cosine similarity: 0.9125203907711272\n",
      "\n",
      "Paper ID: b73191adcc938cfcf20ce0327cf5cd1f539f7f81\n",
      "Title: Scientific Information Extraction with Semi-supervised Neural Tagging\n",
      "Year: 2017\n",
      "Cosine similarity: 0.9105428039253067\n",
      "\n",
      "Paper ID: a550ad9d7f47b65f7788287a23717a4f7c5b75c7\n",
      "Title: Pretrained Language Models for Sequential Sentence Classification\n",
      "Year: 2019\n",
      "Cosine similarity: 0.9039615004641104\n",
      "\n",
      "Paper ID: 81815d9a847e406f8d49fb5051e2ae1055e13208\n",
      "Title: To Pretrain or Not to Pretrain: Examining the Benefits of Pretrainng on Resource Rich Tasks\n",
      "Year: 2020\n",
      "Cosine similarity: 0.8960433498283719\n",
      "\n",
      "Paper ID: f40aeae3e522ada1f6a9f326841b01ef5c8657b6\n",
      "Title: Unifying Language Learning Paradigms\n",
      "Year: 2022\n",
      "Cosine similarity: 0.8932505896810391\n",
      "\n",
      "Paper ID: b271605f2c26f5f37e7283a101b9e05d63be6cd9\n",
      "Title: Community challenges in biomedical text mining over 10 years: success, failure and the future\n",
      "Year: 2016\n",
      "Cosine similarity: 0.8912832494883023\n",
      "\n",
      "Paper ID: 207da6d2c07289bf72a2b5974bb3f011ebb5dd0d\n",
      "Title: Adversarial NLI: A New Benchmark for Natural Language Understanding\n",
      "Year: 2019\n",
      "Cosine similarity: 0.8911491752627466\n",
      "\n",
      "Paper ID: d56c1fc337fb07ec004dc846f80582c327af717c\n",
      "Title: StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding\n",
      "Year: 2019\n",
      "Cosine similarity: 0.8900082723614517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for paper_id, cos_sim in zip(recommended_paper_ids, top_values):\n",
    "    title = metadata[paper_id]['title']\n",
    "    # abstract = metadata[paper_id]['abstract']\n",
    "    year = metadata[paper_id]['year']\n",
    "    print(f'Paper ID: {paper_id}\\nTitle: {title}\\nYear: {year}\\nCosine similarity: {cos_sim}\\n')\n",
    "    cnt += 1 \n",
    "    if cnt == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8b77c547-66da-4e60-b042-f6dac7224145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actual_references = ast.literal_eval(metadata['204e3073870fae3d05bcbc2f6a8e263d9b72e776'].get('references'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "db6b379d-f376-44ba-a4aa-e62d720ae570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def evaluate(recommended, actual):\n",
    "#     recommended = np.asarray(recommended)\n",
    "#     actual = np.asarray(actual)\n",
    "    \n",
    "#     true_positives = np.intersect1d(recommended, actual)\n",
    "#     false_positives = np.setdiff1d(recommended, actual)\n",
    "#     false_negatives = np.setdiff1d(actual, recommended)\n",
    "\n",
    "#     precision = len(true_positives) / (len(true_positives) + len(false_positives))\n",
    "#     recall = len(true_positives) / (len(true_positives) + len(false_negatives))\n",
    "#     f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "#     return precision, recall, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8bfd8c73-c19a-404b-bb95-1cdc4aa7b71f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1956c239b3552e030db1b78951f64781101125ed'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_paper_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b5ffba21-e250-4551-88bd-0782949059cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @ 10: 0.4444444444444444\n",
      "Recall @ 10: 0.10810810810810811\n",
      "F1 Score: 0.17391304347826086\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "precision, recall, f1_score = evaluate(recommended_paper_ids[1:], actual_references, k=k)\n",
    "print(f\"Precision @ {k}: {precision}\")\n",
    "print(f\"Recall @ {k}: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35a052-a97a-4ede-a9ac-54a85b7d6fba",
   "metadata": {},
   "source": [
    "### n = 50\n",
    "Precision: 0.061224489795918366\n",
    "Recall: 0.05454545454545454\n",
    "F1 Score: 0.05769230769230769\n",
    "\n",
    "### n = 500\n",
    "Precision: 0.04408817635270541\n",
    "Recall: 0.4\n",
    "F1 Score: 0.07942238267148015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d559e569-16c3-455a-82c8-6637ecb52a44",
   "metadata": {},
   "source": [
    "# NN-Based Approach to improve P/R/F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a352fc6-9019-4864-b75f-475fd0ecdfe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_map = {}\n",
    "with open('../data/specter/output_10k.json', 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            id = data['paper_id']\n",
    "            # removing the R paper because it has too many citations and makes everything else in graph look tiny\n",
    "            # if id == '659408b243cec55de8d0a3bc51b81173007aa89b':\n",
    "            #     continue\n",
    "            embedding = np.array(data['embedding'])\n",
    "            embedding_map[id] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8536c7a-60b3-403c-8867-f72dc3252124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_paper_ids = list(embedding_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bfe2fd2d-1543-43f4-88e0-f4ae93beaf26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9922"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "717fc65e-6a5a-450b-9731-66a6b9b3f8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_map = {}\n",
    "# fetch references from metadata dict in the format {paper_id: [list of references]}\n",
    "for paper_id in all_paper_ids:\n",
    "    references = ast.literal_eval(metadata[paper_id].get('references'))\n",
    "    reference_map[paper_id] = references or []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "504c2e3d-efe9-4a67-b709-964c11d5036d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RankNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RankNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f416a771-75f1-46a4-8ca0-92d8c6c67958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairwise_ranking_loss(scores, labels, margin=1.0):\n",
    "    diff = labels * (margin - scores)\n",
    "    loss = torch.nn.functional.relu(diff)\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1bfde096-0030-4013-9930-166559f49ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_paper_id='fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5'p=0.1r=0.03571428571428571f1=0.05263157894736841\n",
      "cur_paper_id='a6cb366736791bcccc5c8639de5a8f9636bf87e8'p=0.1r=0.038461538461538464f1=0.05555555555555555\n",
      "cur_paper_id='156d217b0a911af97fa1b5a71dc909ccef7a8028'p=0.0r=0.0f1=0\n",
      "cur_paper_id='bee044c8e8903fb67523c1f8c105ab4718600cdb'p=0.1r=0.05555555555555555f1=0.07142857142857142\n",
      "cur_paper_id='cb92a7f9d9dbcf9145e32fdfa0e70e2a6b828eb1'p=0.2r=0.11764705882352941f1=0.14814814814814817\n"
     ]
    }
   ],
   "source": [
    "num_recommendations = 50\n",
    "K = 10\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for cur_paper_id in all_paper_ids[:5]:\n",
    "    cur_references = reference_map[cur_paper_id]\n",
    "    cur_paper = metadata[cur_paper_id]\n",
    "    top_indices, top_values = find_similar_knn(cur_paper, weights, k=num_recommendations, least=False)\n",
    "    cur_recommendations = [paper_ids[i] for i in top_indices]\n",
    "\n",
    "    # TODO remove this line \n",
    "    cur_recommendations.remove(cur_paper_id)\n",
    "    \n",
    "    p,r,f1 = evaluate(cur_recommendations, cur_references, k=K)\n",
    "    print(f'{cur_paper_id=}{p=}{r=}{f1=}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    for rec in cur_recommendations:\n",
    "        X.append((cur_paper_id, rec))\n",
    "        y.append(1 if rec in cur_references else -1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b782a239-bb5a-4697-bd1a-290e70b286b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2746]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.1548]], grad_fn=<AddmmBackward0>)\n",
      "0.0\n",
      "epoch=0: loss=tensor(0., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 768\n",
    "model = RankNet(embedding_dim * 2, 256)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# loss = torch.nn.MarginRankingLoss(\n",
    "for epoch in range(1):\n",
    "    for i, (cur_id, rec_id) in enumerate(X):\n",
    "        x1 = torch.tensor(embedding_map[cur_id]).float().unsqueeze(0)\n",
    "        x2 = torch.tensor(embedding_map[rec_id]).float().unsqueeze(0)\n",
    "        score1 = model(x1, x2)\n",
    "        score2 = model(x2, x1)\n",
    "        print(score1)\n",
    "        print(score2)\n",
    "        loss = pairwise_ranking_loss(score1 - score2, y[i])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(loss.item())\n",
    "            \n",
    "        break\n",
    "        \n",
    "    print(f'{epoch=}: {loss=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bae045-234a-4f61-9996-24bcabfea402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed0baf-49ee-4bbb-8a68-6ef6a6ddf2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5d3a4c03-45e0-464d-a1ff-cc600214e9ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816c0e0-b44c-49d9-ada8-77e4a5654a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f140b065-07c3-47b9-b439-1be1cf497a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9e4d3-527a-430e-a74a-d35cca103b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da75ce9-f8ba-4be0-b1bb-ac94cffc6c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c7911-b509-4468-b818-900e82ffd9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14726f8-7930-4af3-9b4f-984ba6b3b4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m input_paper, relevant_papers \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtraining_set\u001b[49m:\n\u001b[1;32m     34\u001b[0m         pos_score \u001b[38;5;241m=\u001b[39m model(input_paper)\n\u001b[1;32m     35\u001b[0m         neg_scores \u001b[38;5;241m=\u001b[39m [model(paper) \u001b[38;5;28;01mfor\u001b[39;00m paper \u001b[38;5;129;01min\u001b[39;00m training_set \u001b[38;5;28;01mif\u001b[39;00m paper \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m relevant_papers]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_set' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class PaperRankingNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(PaperRankingNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def pairwise_ranking_loss(pos_score, neg_score):\n",
    "    return torch.mean(torch.relu(1 - (pos_score - neg_score)))\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = 768\n",
    "hidden_dim = 512\n",
    "model = PaperRankingNet(input_dim, hidden_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = pairwise_ranking_loss\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for input_paper, relevant_papers in training_set:\n",
    "        pos_score = model(input_paper)\n",
    "        neg_scores = [model(paper) for paper in training_set if paper not in relevant_papers]\n",
    "        loss = sum([criterion(pos_score, neg_score) for neg_score in neg_scores])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "for input_paper, actual_references in testing_set:\n",
    "    scores = {paper: model(input_paper) for paper in training_set}\n",
    "    ranked_papers = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)\n",
    "    recommended_papers = ranked_papers[:10]\n",
    "    precision = len(set(recommended_papers) & set(actual_references)) / len(recommended_papers)\n",
    "    recall = len(set(recommended_papers) & set(actual_references)) / len(actual_references)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "206457ab4910b064b67455bd75e50e17d8a95a06b82e237351ff89b18574f0fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
